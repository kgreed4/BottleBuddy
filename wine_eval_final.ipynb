{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8172,
          "sourceType": "datasetVersion",
          "datasetId": 1442
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgreed4/BottleBuddy/blob/kgreed/wine_eval_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_dF8WJoidvm",
        "outputId": "3191d178-ddbb-4801-cbcf-999ec61c301c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (676 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.6.1 pymongo-4.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyt__-yCipGz",
        "outputId": "aeca9c4b-dbb1-48e3-ebc9-9380d615c2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.17.1-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4L9xkBRnzrk",
        "outputId": "455fa9be-5216-4676-dc95-67b61593fc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "import certifi\n",
        "import pymongo.errors as mongo_errors\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# Here we create the openai object and set the API key so that we can use the OpenAI API.\n",
        "openai.api_key = 'your_openai_api_key'\n",
        "\n",
        "def get_database():\n",
        "    \"\"\"\n",
        "    Purpose: Establish a connection to the MongoDB database.\n",
        "    \"\"\"\n",
        "    uri = \"mongodb+srv://sriveerisetti:Wine@wine.kdvgm.mongodb.net/?retryWrites=true&w=majority&appName=Wine\"\n",
        "    ca = certifi.where()\n",
        "\n",
        "    try:\n",
        "        client = MongoClient(uri, tlsCAFile=ca)\n",
        "        client.list_database_names()\n",
        "        # The name of the database is 'BottleBuddy'.\n",
        "        db = client['BottleBuddy']\n",
        "        print(\"Successfully connected to the database.\")\n",
        "        return db\n",
        "    except mongo_errors.ConnectionFailure as e:\n",
        "        print(f\"Could not connect to MongoDB: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "def generate_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    \"\"\"\n",
        "    Purpose: Generate an embedding for the given text using the specified model.\n",
        "    Input: text - The text for which an embedding is to be generated.\n",
        "    Input: model - The model to use for generating the embedding.\n",
        "    \"\"\"\n",
        "    response = openai.Embedding.create(input=[text], model=model)\n",
        "    embedding = response['data'][0]['embedding']\n",
        "    return embedding\n",
        "\n",
        "def store_row_with_embedding(custom_id, title, description, collection):\n",
        "    \"\"\"\n",
        "    Purpose: Store the title, description, and its embedding in the database with a custom ID.\n",
        "    Input: custom_id - The custom ID to use for the document.\n",
        "    Input: title - The title of the content.\n",
        "    Input: description - The description of the content.\n",
        "    Input: collection - The MongoDB collection in which to store the document.\n",
        "    \"\"\"\n",
        "    combined_text = title + \" \" + description\n",
        "    # Here we use the generate_embedding function to generate the embedding for the combined text.\n",
        "    embedding = generate_embedding(combined_text)\n",
        "    collection.insert_one({\n",
        "        \"_id\": custom_id,\n",
        "        \"title\": title,\n",
        "        \"description\": description,\n",
        "        \"openai_embedding\": embedding\n",
        "    })\n",
        "    # I want to make sure that the content has been stored successfully in the database so we print a message after every row\n",
        "    # is added to the MongoDB collection.\n",
        "    print(f\"Content with title '{title}' has been successfully stored in MongoDB with ID {custom_id}.\")\n",
        "\n",
        "# The main function that will be executed when the script is run.\n",
        "if __name__ == \"__main__\":\n",
        "    db = get_database()\n",
        "    if db is not None:\n",
        "        # Define the collection\n",
        "        collection = db['Wine']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMImwfzFibmd",
        "outputId": "7a2108f7-2823-45c4-e8ac-d8f35cb952b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully connected to the database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "'''\n",
        "This script is responsible for embedding the user_data and returning the embeddings.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Embed user_data using the model.\n",
        "\n",
        "Parameters:\n",
        "user_data - user_data to embed\n",
        "model_name - name of the model to use, default is 'avsolatorio/GIST-Embedding-v0'\n",
        "\n",
        "Return:\n",
        "embedding - embedding of the query\n",
        "'''\n",
        "def generate_gist_embedding(user_data, model_name='avsolatorio/GIST-Embedding-v0'):\n",
        "    # Initialize the SentenceTransformer\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    # Embed the query\n",
        "    embedding = model.encode([user_data], convert_to_tensor=True)\n",
        "\n",
        "    # Convert embedded query tensor to list before querying the index\n",
        "    embedding = embedding[0].squeeze().tolist()\n",
        "\n",
        "    return embedding"
      ],
      "metadata": {
        "trusted": true,
        "id": "6rFAoUYpa18b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_openai_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    \"\"\"\n",
        "    Purpose: Generate an embedding for the given text using the specified model.\n",
        "    Input: text - The text for which an embedding is to be generated.\n",
        "    Input: model - The model to use for generating the embedding.\n",
        "    \"\"\"\n",
        "    #client = openai.Client(OPENAI_API_KEY)\n",
        "    openai.api_key = 'your-openai-api-key'\n",
        "    response = openai.Embedding.create(input=text, model=model)\n",
        "    embedding = response['data'][0]['embedding']\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "hC1pt9rjmNSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_data(embedding, name, k=5):\n",
        "    \"\"\"\n",
        "    Fetch similar embeddings from MongoDB database using a vector search.\n",
        "    \"\"\"\n",
        "    query = [\n",
        "        {\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": f\"{name}_index\",\n",
        "                \"path\": f\"{name}_embeddings\",\n",
        "                \"queryVector\": embedding,\n",
        "                \"numCandidates\": 50,\n",
        "                \"limit\": k\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    try:\n",
        "        results = list(collection.aggregate(query))\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing vector search in MongoDB: {e}\")\n",
        "        results = []  # Return an empty list in case of error\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "kOZb1Cw9baEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data = ['apple', 'sweet', 'light-bodied']\n",
        "gist_input = generate_gist_embedding(user_data)\n",
        "gist_results = fetch_data(gist_input, 'gist')"
      ],
      "metadata": {
        "id": "dJ59ycgri9Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_input = generate_openai_embedding(user_data)\n",
        "openai_results = fetch_data(openai_input, 'openai')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etDoGtKIoazN",
        "outputId": "72a5204f-03c6-4ea8-fd0a-f4976d978969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error performing vector search in MongoDB: PlanExecutor error during aggregation :: caused by :: openai_embeddings is not indexed as knnVector, full error: {'ok': 0.0, 'errmsg': 'PlanExecutor error during aggregation :: caused by :: openai_embeddings is not indexed as knnVector', 'code': 8, 'codeName': 'UnknownError', '$clusterTime': {'clusterTime': Timestamp(1713115774, 1), 'signature': {'hash': b'\\x98\\xbbU\\xcc\\xdc\\x9e\\xad\\xcf\\xaf\\xae\\xdb\\x076*\\x94M\\x10\\x82[R', 'keyId': 7355934919572324358}}, 'operationTime': Timestamp(1713115774, 1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = []\n",
        "for result in gist_results:\n",
        "    results_list.append(result['title'])\n",
        "\n",
        "print(results_list)\n",
        "\n",
        "results_2 = []\n",
        "for result in openai_results:\n",
        "    results_2.append(result['title'])\n",
        "\n",
        "print(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yapyRioakIq-",
        "outputId": "f4840f23-f64d-4619-8303-97d22992b128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cavas Hill NV 1887 Rosado Sparkling (Cava)', 'Michel Torino 2006 Coleccion Chardonnay (Calchaquí Valley)', 'Michel Torino 2006 Coleccion Chardonnay (Calchaquí Valley)', 'Gunter Triebaumer NV Muscato Moscato (Österreichischer Sekt)', 'Domaine Jean-Paul et Benoît Droin 2010  Chablis']\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_evaluation(tasters, data, points):\n",
        "    \"\"\"\n",
        "    Run evaluation on model: for evaluation, we consider each taster's top 10 wines based on the points given.\n",
        "    For each of the top 10, we look at the 5 most similar vectors as recommendations, and see what percentage of the\n",
        "    recommended wines were within <5 points of the original top10 wine of each taster-- thus demonstrating similar interest\n",
        "\n",
        "    parameters:\n",
        "        tasters: list of unique taster_name in the original dataset\n",
        "        data: data that includes the points given to each wine by each taster\n",
        "        points: threshold to be within\n",
        "    returns: percentage value of how often the recommended wines were within <5 points of original top-10 wine for each user\n",
        "    \"\"\"\n",
        "    final_percentages_recommended_less5difference = []\n",
        "    wine_names = data['title']\n",
        "    for name in tasters:\n",
        "        tasters_differences = []\n",
        "        voted_wines =  data[data['taster_name']==name]\n",
        "        voted_wines.sort_values(by='points', ascending=False, inplace = True)\n",
        "\n",
        "        voters_top_10 = voted_wines.head(10)\n",
        "        point_values = voters_top_10['points'].tolist()\n",
        "        indexes = voters_top_10.index.tolist()\n",
        "        for i in range(len(indexes)):\n",
        "            recommended_point_differences = []\n",
        "            index_value = indexes[i]\n",
        "            reference_index = index_value # Adjust as needed\n",
        "            reference_wine = data.loc[reference_index]['description']\n",
        "            # reference_wine = scaled_data[reference_index].reshape(1, -1)  # Reshape to match the input format expected by kneighbors\n",
        "            # _, indices = model.kneighbors(reference_wine)\n",
        "            reference_desc = generate_gist_embedding(reference_wine)\n",
        "            gist_results = fetch_data(reference_desc, 'gist', 10)\n",
        "            results_list = []\n",
        "            for result in gist_results:\n",
        "                results_list.append(result['title'])\n",
        "\n",
        "            nearest_neighbor_names = results_list\n",
        "\n",
        "            #get the points\n",
        "            for nearest_neighbor_name in nearest_neighbor_names:\n",
        "                if nearest_neighbor_name in voted_wines['title'].values:\n",
        "                    # Get the row where the name is present in the 'title' column\n",
        "                    row = voted_wines[voted_wines['title'] == nearest_neighbor_name]\n",
        "                    # Get the points column value from the row\n",
        "                    difference = abs(point_values[i]-row['points'].values[0])\n",
        "                    recommended_point_differences.append(difference)\n",
        "            meets_threshold_count = 0\n",
        "            for x in recommended_point_differences:\n",
        "                if x<=points:\n",
        "                    meets_threshold_count+=1\n",
        "            if len(recommended_point_differences)!=0:\n",
        "                tasters_differences.append(meets_threshold_count/len(recommended_point_differences))\n",
        "        if len(tasters_differences)!=0:\n",
        "            final_percentages_recommended_less5difference.append(sum(tasters_differences)/len(tasters_differences))\n",
        "    return final_percentages_recommended_less5difference"
      ],
      "metadata": {
        "id": "7B0WvOD3a31Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/data_first10k.csv')\n",
        "\n",
        "data = pd.get_dummies(df, columns=['country', 'designation', 'province', 'variety', 'winery' ])\n",
        "\n",
        "tasters = data['taster_name'].unique().tolist()"
      ],
      "metadata": {
        "id": "QxT21usvrwpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evalution for gist with 5 point threshold\n",
        "gist_eval_5 = run_evaluation(tasters, data, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPM4q45wt0js",
        "outputId": "bee33089-2ae2-420e-85e7-8e6b6324ff6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-ce0dd28aec8c>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  voted_wines.sort_values(by='points', ascending=False, inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Within 5 points: ', gist_eval_10)\n",
        "avg_gist_eval_5 = sum(gist_eval_5)/len(gist_eval_5)\n",
        "print('Average of gist 5: ', avg_gist_eval_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHa0r2xdt9Ki",
        "outputId": "35fc788e-2c54-4872-e6e6-1ce8830fc375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Within 5 points:  [0.818888888888889, 0.5127777777777778, 0.7999999999999999, 1.0, 0.78, 0.8177777777777779, 0.7538888888888888, 0.7388888888888889, 0.9023809523809524, 0.8547619047619047, 0.8547619047619047, 0.951388888888889, 0.9666666666666668, 1.0, 0.95, 0.8511904761904763, 1.0, 1.0]\n",
            "Average of gist 5:  0.864076278659612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Create one bar graph each evaluator in gist_eval_10\n",
        "for i in range(len(gist_eval_10)):\n",
        "    plt.bar(i, gist_eval_10[i], color='blue')\n",
        "    plt.xlabel('Taster')\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.title('Percentage of recommended wines within 5 points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GuYjI9mM7OLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}